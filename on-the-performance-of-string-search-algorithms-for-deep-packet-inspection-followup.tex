\documentclass[11pt]{article}
\usepackage[round]{natbib}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{pgf}
\usepackage[most]{tcolorbox}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{inconsolata}
\usepackage{cleveref}
\usepackage[inline]{enumitem}
\usepackage{dcolumn}
\usepackage{booktabs}

\usepackage[scaled]{helvet}
\renewcommand\familydefault{\sfdefault}
\usepackage[T1]{fontenc}

\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}
\definecolor{atomred}{RGB}{224, 108, 117}
\definecolor{atomwhite}{RGB}{250, 250, 250}

\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{atomred}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\lstset{
   language=JavaScript,
   backgroundcolor=\color{atomwhite},
   extendedchars=true,
   basicstyle=\ttfamily\footnotesize,
   showstringspaces=false,
   showspaces=false,
   numbers=left,
   numberstyle=\ttfamily\footnotesize,
   numbersep=5pt,
   tabsize=2,
   breaklines=true,
   showtabs=false,
   captionpos=b,
   frame=single
}

\begin{document}

\title{On the Performance of String Search Algorithms for Deep Packet Inspection - Followup}
\author{Kieran Hunt}
\date{\today}
\maketitle

%TODO: Abstract

\section{Processing Speed vs Input Length} \label{sec-processingspeecvsinputlength}

In a previous paper by \citet{hunt2016}, a selection of DNS traffic was used as input for the comparison between algorithm processing time and input length. The average length of a packet from that dataset was near 110 bytes. While that length made sense for dns traffic - notoriously low bandwidth usage - it did mean that a true reflection of algorithmic performance could not be obtained for longer length packets. A dataset of randomly generated DNS traffic was produced with a maximum length of 1500 bytes (the maximum transmission unit for ethernet) and a mean length of 770 bytes. The new set of packets is hereafter referred to as \textit{Dataset C}. More information can be found in Table \ref{table-datasetcinputlengthsummary}.

\begin{table}[!htb]
\centering
\begin{tabular}{@{}llllll@{}}
\toprule
Min & First Quartile & Median & Mean & Third Quartile & Max \\ \midrule
44 & 407 & 763.5 & 770.9 & 1136 & 1500 \\ \bottomrule
\end{tabular}
\caption{A summary of the input lengths in \textit{Dataset C}}
\label{table-datasetcinputlengthsummary}
\end{table}

Each of the four algorithms was tested for the same rules as in \citet{hunt2016} and with \textit{Dataset C} as input. Figure \ref{figure-individualalgorithmsvslength} shows a comparison between each of the algorithms.


\begin{figure}[!htb]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{images/processing_speed_vs_input_length_no_matches_Horspool}
      \caption{Horspool}
      \label{figure-processingtimevslengthhorspool}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{images/processing_speed_vs_input_length_no_matches_QuickSearch}
      \caption{QuickSearch}
      \label{figure-processingtimevslengthquicksearch}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{images/processing_speed_vs_input_length_no_matches_NotSoNaive}
      \caption{NotSoNaive}
      \label{figure-processingtimevslengthnotsonaive}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{images/processing_speed_vs_input_length_no_matches_RabinKarp}
      \caption{RabinKarp}
      \label{figure-processingtimevslengthrabinkarp}
  \end{subfigure}
  \caption{Mean processing times versus input length for the Horspool, QuickSearch, NotSoNaive, and RabinKarp algorithms for \textit{Dataset C}.}
  \label{figure-individualalgorithmsvslength}
\end{figure}

From Figure \ref{figure-individualalgorithmsvslength}, it is clear that the processing times for Horspool and QuickSearch (Subfigures \ref{figure-processingtimevslengthhorspool} and \ref{figure-processingtimevslengthquicksearch} respectively) do not rise as quickly as those of NotSoNaive and RabinKarp (Subfigures \ref{figure-processingtimevslengthnotsonaive} and \ref{figure-processingtimevslengthrabinkarp} respectively) for inputs of greater length. Both NotSoNaive and RabinKarp show an exponential rise in processing times. 

Horspool and QuickSearch also show initial humps in processing speed around the 250 byte mark. This can be attributed to the overheard associated with each packet. For packets of more than 250 bytes, the processing speed relies more on the length of the packet then the initial - per-packet - overhead. This initial hump is not evident on either NotSoNaive nor RabinKarp; the reason for this is twofold. First, the speed of these algorithms is more affected by the input length, because of this an initial hump would be surpassed by the time it takes to process each packet. Second, the vertical scale of these two graphs is much larger than that Horspool or QuickSearch. Owing to that a small hump earlier on is less visible on a larger scale.


\section{Processing Speed vs Number of Matches}

For Section \ref{sec-processingspeecvsinputlength}, \textit{Dataset C} was created. It was designed in such a way that the number of matches in the input would not affect the processing speed. The processing speed was thus only affected by the length of the input and the algorithm used. In order to compare the processing speed against different numbers of matches, another Dataset needed to be created. \textit{Dataset D} contains 10000 DNS packets. Each 1500 bytes long. The payload in \textit{Dataset D} contains a mixture of randomized text and repeated strings of the rules. Each packet therefore contains between 0 and 1500 bytes of characters which are known to match with the rules used. This input data isolates the number of matches from the length of the input.

%TODO: Change the following images to their correct files.

\begin{figure}[!htb]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{images/processing_speed_vs_input_length_no_matches_Horspool}
      \caption{Horspool}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{images/processing_speed_vs_input_length_no_matches_QuickSearch}
      \caption{QuickSearch}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{images/processing_speed_vs_input_length_no_matches_NotSoNaive}
      \caption{NotSoNaive}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
      \includegraphics[width=\textwidth]{images/processing_speed_vs_input_length_no_matches_RabinKarp}
      \caption{RabinKarp}
  \end{subfigure}
  \caption{Mean processing times for each algorithm vs number of matches. \textit{Dataset D}.}
  \label{figure-individualalgorithmsvsnumberofmatches}
\end{figure}


\section{Parallelism}


\bibliographystyle{plainnat}
\bibliography{references}

\end{document}